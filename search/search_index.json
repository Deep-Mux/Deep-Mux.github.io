{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to Deep Mux Official website DeepMux is a platform to deploy machine learning models into production. Our system allows you to use only as much GPU time as you really need. We automatically pick the best hardware that suits your model. Simply upload your model and get predictions, zero tweaking required.","title":"Overview"},{"location":"#welcome-to-deep-mux","text":"Official website DeepMux is a platform to deploy machine learning models into production. Our system allows you to use only as much GPU time as you really need. We automatically pick the best hardware that suits your model. Simply upload your model and get predictions, zero tweaking required.","title":"Welcome to Deep Mux"},{"location":"details/","text":"Cold start Model inference time may increase after model has been idle for some time. It happens due to the fact that we need to load model into the memory before executing it. Increase in latency depends on the model size. E.g. for 200MB model it would take about 500ms to load. You can project loading time onto your model as it scales linearly. Time after which model is unloaded is not fixed and is subject to constant adjustment. Think tens of seconds to minutes. If the model is loaded when a request occurs there is 2-3 ms of latency per request added by the infrastructure. Billing You are charged only for inference time and not for any kind of infrastructure latency. Note that request times on the client may differ from the ones observed in monitoring due to network latency / throughput.","title":"Details"},{"location":"details/#cold-start","text":"Model inference time may increase after model has been idle for some time. It happens due to the fact that we need to load model into the memory before executing it. Increase in latency depends on the model size. E.g. for 200MB model it would take about 500ms to load. You can project loading time onto your model as it scales linearly. Time after which model is unloaded is not fixed and is subject to constant adjustment. Think tens of seconds to minutes. If the model is loaded when a request occurs there is 2-3 ms of latency per request added by the infrastructure.","title":"Cold start"},{"location":"details/#billing","text":"You are charged only for inference time and not for any kind of infrastructure latency. Note that request times on the client may differ from the ones observed in monitoring due to network latency / throughput.","title":"Billing"},{"location":"faq/","text":"FAQ What if my model is written in a framework that is not supported by DeepMux? We support models in ONNX format, which is quite universal. You can convert your model to ONNX and uplad it to deepmux. If it is not possible, feel free to contact us at dev@deepmux.com and we will figure out a solution for you. What if model has multiple inputs / outputs? To create a model with multiple inputs / outputs, you need to pass a list of shapes into input_shape and output_shape parameters. For example, [[2, 2], [1, 3]] would stand for two inputs of sizes 2x2 and 1x3 respectively. Are variable input / output sizes supported? Short answer would be: not yet. Nevertheless you can create a model and predefine it's expected input shape to resize your input before passing it to the model. Variable output shapes are not possible at the moment.","title":"FAQ"},{"location":"faq/#faq","text":"","title":"FAQ"},{"location":"faq/#what-if-my-model-is-written-in-a-framework-that-is-not-supported-by-deepmux","text":"We support models in ONNX format, which is quite universal. You can convert your model to ONNX and uplad it to deepmux. If it is not possible, feel free to contact us at dev@deepmux.com and we will figure out a solution for you.","title":"What if my model is written in a framework that is not supported by DeepMux?"},{"location":"faq/#what-if-model-has-multiple-inputs-outputs","text":"To create a model with multiple inputs / outputs, you need to pass a list of shapes into input_shape and output_shape parameters. For example, [[2, 2], [1, 3]] would stand for two inputs of sizes 2x2 and 1x3 respectively.","title":"What if model has multiple inputs / outputs?"},{"location":"faq/#are-variable-input-output-sizes-supported","text":"Short answer would be: not yet. Nevertheless you can create a model and predefine it's expected input shape to resize your input before passing it to the model. Variable output shapes are not possible at the moment.","title":"Are variable input / output sizes supported?"},{"location":"client-libraries/http/","text":"DeepMux HTTP API You are here probably because you haven't found an SDK that suits your language / platform. Feel free to notify devs that you actually need a convenient library for your language by contacting us via dev@deepmux.com . Full documentation for HTTP API is availible at api.deepmux.com/docs/v1/ in swagger format, since it is much more useful than static docs.","title":"HTTP API"},{"location":"client-libraries/http/#deepmux-http-api","text":"You are here probably because you haven't found an SDK that suits your language / platform. Feel free to notify devs that you actually need a convenient library for your language by contacting us via dev@deepmux.com . Full documentation for HTTP API is availible at api.deepmux.com/docs/v1/ in swagger format, since it is much more useful than static docs.","title":"DeepMux HTTP API"},{"location":"client-libraries/python/","text":"DeepMux Python client library deepmux is a PaaS solution to effortlessly deploy trained machine learning models on the cloud and generate predictions without setting up any hardware. At the moment only pytorch models are supported. API Token To use deepmux-python you will need an API token. You can always get one here: app.deepmux.com/api_key Installation pip install deepmux Creating models You can always create a model using create_model function. from deepmux import create_model There are multiple parameters you need to pass to create_model function: pytorch_model : Pre-trained pytorch model. Once the model is uploaded model_name : Model name by which you can refer to it once it is uploaded. input_shape : List of input tensor shapes for each model input. A typical model would work with input shape of [[1, 3, 224, 224]] . Note the nested list, if your model has multiple inputs, you can pass input shapes in the topmost list like this: [[2, 2], [1, 3]] that would stand for two inputs of sizes 2x2 and 1x3 respectively. output_shape : List of output tensor shapes for each model input. Semantics are the same as the same as for input_shape . Below is an artificial example of creating a model with two inputs and a single output: import torch from deepmux import create_model class MyNet(torch.nn.Module): def __init__(self): super().__init__() self.model1 = torch.nn.Sequential( torch.nn.Linear(2, 4), torch.nn.ReLU() ) self.model2 = torch.nn.Sequential( torch.nn.Linear(8, 4), ) def forward(self, x, y): x1 = self.model1(x) y1 = self.model1(y) return self.model2(torch.cat((x1, y1), 0)) net = MyNet() # Train or load weights # ... token = '<YOUR API TOKEN>' deepmux_model = create_model( net, model_name='my_net', input_shape=[[2], [2]], output_shape=[4], token=token) Getting models by name Once the model was created you can refer to the model by it's name. This function is useful in production environment since you don't need to know anything about the model apart from it's name to execute it. Going forward with the example from previous point: from deepmux import get_model token = '<YOUR API TOKEN>' deepmux_model = get_model('my_net', token) Running models After initializing your model with create_model or get_model you can run the model. All computations will be performed on deepmux infrastucture. To run the model you must pass a numpy.ndarray for each input. Shapes of input tensors must match model input shapes. Note that dtype of the input data must match the data type of the uploaded model. Again, with our MyNet example: model_input = [ np.array([2.0, 3.0], dtype=np.float32), np.array([2.0, 3.0], dtype=np.float32) ] output = deepmux_model.run(*model_input) Example from the tutorial import torch from deepmux import create_model # Initialize a PyTorch model class MyNet(torch.nn.Module): def __init__(self): super().__init__() self.model1 = torch.nn.Sequential( torch.nn.Linear(2, 4), torch.nn.ReLU() ) self.model2 = torch.nn.Sequential( torch.nn.Linear(8, 4), ) def forward(self, x, y): x1 = self.model1(x) y1 = self.model1(y) return self.model2(torch.cat((x1, y1), 0)) # Not training the model and using default weights here net = MyNet() # Upload model to DeepMux token = '<YOUR API TOKEN>' deepmux_model = create_model( net, model_name='my_net', input_shape=[[2], [2]], output_shape=[4], token=token) # get_model call is redundant here since create_model returns a reference to the model # deepmux_model = get_model('my_net', token) # Run model model_input = [ np.array([2.0, 3.0], dtype=np.float32), np.array([2.0, 3.0], dtype=np.float32) ] output = deepmux_model.run(*model_input) Example on a model from PyTorch Hub Below is an example of a complete ImageNet classifier achieved with pretrained squeezenet model. Creating the model import numpy as np import torch from deepmux import create_model token = \"<YOUR API TOKEN>\" pytorch_model = torch.hub.load('pytorch/vision:v0.5.0', 'squeezenet1_0', pretrained=True) create_model( pytorch_model, model_name='my_squeezenet', input_shape=[1, 3, 227, 227], output_shape=[1, 1000], token=token) Running the model # Note: we no longer need pytorch from deepmux import get_model token = \"<YOUR API TOKEN>\" deepmux_model = get_model('my_squeezenet', token) dummy_input = np.zeros([1, 3, 227, 227], dtype=np.float32) output = deepmux_model.run(dummy_input) Colab demo Try our demo or contact us at dev@deepmux.com if you have any questions left.","title":"Python"},{"location":"client-libraries/python/#deepmux-python-client-library","text":"deepmux is a PaaS solution to effortlessly deploy trained machine learning models on the cloud and generate predictions without setting up any hardware. At the moment only pytorch models are supported.","title":"DeepMux Python client library"},{"location":"client-libraries/python/#api-token","text":"To use deepmux-python you will need an API token. You can always get one here: app.deepmux.com/api_key","title":"API Token"},{"location":"client-libraries/python/#installation","text":"pip install deepmux","title":"Installation"},{"location":"client-libraries/python/#creating-models","text":"You can always create a model using create_model function. from deepmux import create_model There are multiple parameters you need to pass to create_model function: pytorch_model : Pre-trained pytorch model. Once the model is uploaded model_name : Model name by which you can refer to it once it is uploaded. input_shape : List of input tensor shapes for each model input. A typical model would work with input shape of [[1, 3, 224, 224]] . Note the nested list, if your model has multiple inputs, you can pass input shapes in the topmost list like this: [[2, 2], [1, 3]] that would stand for two inputs of sizes 2x2 and 1x3 respectively. output_shape : List of output tensor shapes for each model input. Semantics are the same as the same as for input_shape . Below is an artificial example of creating a model with two inputs and a single output: import torch from deepmux import create_model class MyNet(torch.nn.Module): def __init__(self): super().__init__() self.model1 = torch.nn.Sequential( torch.nn.Linear(2, 4), torch.nn.ReLU() ) self.model2 = torch.nn.Sequential( torch.nn.Linear(8, 4), ) def forward(self, x, y): x1 = self.model1(x) y1 = self.model1(y) return self.model2(torch.cat((x1, y1), 0)) net = MyNet() # Train or load weights # ... token = '<YOUR API TOKEN>' deepmux_model = create_model( net, model_name='my_net', input_shape=[[2], [2]], output_shape=[4], token=token)","title":"Creating models"},{"location":"client-libraries/python/#getting-models-by-name","text":"Once the model was created you can refer to the model by it's name. This function is useful in production environment since you don't need to know anything about the model apart from it's name to execute it. Going forward with the example from previous point: from deepmux import get_model token = '<YOUR API TOKEN>' deepmux_model = get_model('my_net', token)","title":"Getting models by name"},{"location":"client-libraries/python/#running-models","text":"After initializing your model with create_model or get_model you can run the model. All computations will be performed on deepmux infrastucture. To run the model you must pass a numpy.ndarray for each input. Shapes of input tensors must match model input shapes. Note that dtype of the input data must match the data type of the uploaded model. Again, with our MyNet example: model_input = [ np.array([2.0, 3.0], dtype=np.float32), np.array([2.0, 3.0], dtype=np.float32) ] output = deepmux_model.run(*model_input)","title":"Running models"},{"location":"client-libraries/python/#example-from-the-tutorial","text":"import torch from deepmux import create_model # Initialize a PyTorch model class MyNet(torch.nn.Module): def __init__(self): super().__init__() self.model1 = torch.nn.Sequential( torch.nn.Linear(2, 4), torch.nn.ReLU() ) self.model2 = torch.nn.Sequential( torch.nn.Linear(8, 4), ) def forward(self, x, y): x1 = self.model1(x) y1 = self.model1(y) return self.model2(torch.cat((x1, y1), 0)) # Not training the model and using default weights here net = MyNet() # Upload model to DeepMux token = '<YOUR API TOKEN>' deepmux_model = create_model( net, model_name='my_net', input_shape=[[2], [2]], output_shape=[4], token=token) # get_model call is redundant here since create_model returns a reference to the model # deepmux_model = get_model('my_net', token) # Run model model_input = [ np.array([2.0, 3.0], dtype=np.float32), np.array([2.0, 3.0], dtype=np.float32) ] output = deepmux_model.run(*model_input)","title":"Example from the tutorial"},{"location":"client-libraries/python/#example-on-a-model-from-pytorch-hub","text":"Below is an example of a complete ImageNet classifier achieved with pretrained squeezenet model.","title":"Example on a model from PyTorch Hub"},{"location":"client-libraries/python/#creating-the-model","text":"import numpy as np import torch from deepmux import create_model token = \"<YOUR API TOKEN>\" pytorch_model = torch.hub.load('pytorch/vision:v0.5.0', 'squeezenet1_0', pretrained=True) create_model( pytorch_model, model_name='my_squeezenet', input_shape=[1, 3, 227, 227], output_shape=[1, 1000], token=token)","title":"Creating the model"},{"location":"client-libraries/python/#running-the-model","text":"# Note: we no longer need pytorch from deepmux import get_model token = \"<YOUR API TOKEN>\" deepmux_model = get_model('my_squeezenet', token) dummy_input = np.zeros([1, 3, 227, 227], dtype=np.float32) output = deepmux_model.run(dummy_input)","title":"Running the model"},{"location":"client-libraries/python/#colab-demo","text":"Try our demo or contact us at dev@deepmux.com if you have any questions left.","title":"Colab demo"}]}